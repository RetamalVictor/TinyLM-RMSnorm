name: long
steps: 50000
batch_size: 32
seq_len: 512

# Optimizer
lr: 3e-4
weight_decay: 0.1
betas: [0.9, 0.95]

# Learning rate schedule
lr_schedule: cosine
warmup_steps: 500
min_lr_ratio: 0.1

# Gradient handling
grad_clip: 1.0
grad_accum_steps: 2

# Mixed precision
mixed_precision: true

# Early stopping (0 = disabled)
early_stopping_patience: 0
early_stopping_min_delta: 0.0
