name: large
architecture: llama  # llama or gpt
dim: 768
n_layers: 12
n_heads: 12
dropout: 0.1
max_seq_len: 4096
gradient_checkpointing: false
