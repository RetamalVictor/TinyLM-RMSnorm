services:
  nanofalcon:
    shm_size: "16g"
    environment:
      PYTORCH_CUDA_ALLOC_CONF: "max_split_size_mb:256"
    command: >
      bash -lc "
        python data/prepare_tinystories.py &&
        python setup_cuda.py build_ext --inplace &&
        pytest -q &&
        python train.py
          --data tinystories
          --steps 4000
          --batch_size 24
          --seq_len 512
          --dim 768
          --n_layers 12
          --n_heads 12
          --lr 2.5e-4
          --compile &&
        python infer.py --ckpt out/best.pt --prompt 'Once upon a time in Abu Dhabi' --max_new_tokens 120
      "
